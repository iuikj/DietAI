import os
from dotenv import load_dotenv
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.docstore.document import Document
from shared.config.settings import get_settings

settings = get_settings()
# âœ… ä½ çš„æ–‡æ¡£è·¯å¾„
DOC_PATH = os.path.join(settings.DOC_PATH, "nutrition_knowledge.txt")

# âœ… Chroma æŒä¹…åŒ–è·¯å¾„
PERSIST_DIRECTORY = settings.VECTOR_STORE_PATH

# âœ… collection åç§°ï¼ˆå¯è‡ªå®šä¹‰ï¼‰
COLLECTION_NAME = settings.VECTOR_COLLECTION_NAME

# âœ… è¯»å–æ–‡æ¡£
with open(DOC_PATH, "r", encoding="utf-8") as f:
    raw_text = f.read()

# âœ… åˆ‡åˆ† chunk
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=100,
)
chunks = text_splitter.split_text(raw_text)

# âœ… è½¬æ¢ä¸º Document å¯¹è±¡
docs = [Document(page_content=chunk) for chunk in chunks]

load_dotenv(f".env", override=True)
# âœ… åˆå§‹åŒ– Embeddings
embeddings = OpenAIEmbeddings()  # éœ€è¦è®¾ç½® OPENAI_API_KEY

# âœ… åˆ›å»º Chroma Vector Storeï¼ˆå¦‚æœç›®å½•å­˜åœ¨åˆ™ä¼šè¿½åŠ ï¼‰
vectorstore = Chroma(
    collection_name=COLLECTION_NAME,
    embedding_function=embeddings,
    persist_directory=PERSIST_DIRECTORY,
)

# âœ… æ·»åŠ æ–‡æ¡£å¹¶æŒä¹…åŒ–
vectorstore.add_documents(docs)

print("âœ… Chroma vector store å·²ä¿å­˜åˆ°ï¼š", PERSIST_DIRECTORY)


# ========================
# âœ… æµ‹è¯•æ£€ç´¢
# ========================
# é‡æ–°åŠ è½½
vectorstore = Chroma(
    collection_name=COLLECTION_NAME,
    embedding_function=embeddings,
    persist_directory=PERSIST_DIRECTORY,
)

# æµ‹è¯•æŸ¥è¯¢
query = "æ€ä¹ˆå¹³è¡¡è›‹ç™½è´¨ã€ç¢³æ°´å’Œè„‚è‚ªæ‘„å…¥ï¼Ÿ"
results = vectorstore.similarity_search(query, k=3)

print("\n=== ğŸ” æ£€ç´¢ç»“æœ ===")
for i, res in enumerate(results):
    print(f"\nChunk {i+1}:\n{res.page_content}")
